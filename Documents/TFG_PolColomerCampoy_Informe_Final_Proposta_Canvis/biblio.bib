%% CITES I BIBLIOGRAFIA
% ICA
@article{ICA_Sawada_Ono_Kameoka_Kitamura_Saruwatari_2019, title={A review of blind source separation methods: two converging routes to ILRMA originating from ICA and NMF}, volume={8}, DOI={10.1017/ATSIP.2019.5}, journal={APSIPA Transactions on Signal and Information Processing}, author={Sawada, Hiroshi and Ono, Nobutaka and Kameoka, Hirokazu and Kitamura, Daichi and Saruwatari, Hiroshi}, year={2019}, pages={e12}}

@article{ICA_hyvarinen2000independent,
  title={Independent component analysis: algorithms and applications},
  author={Hyvarinen, Aapo and Oja, Erkki},
  journal={Neural networks},
  volume={13},
  number={4-5},
  pages={411--430},
  year={2000},
  publisher={Elsevier}
}
@article{langlois2010introduction,
  title={An introduction to independent component analysis: InfoMax and FastICA algorithms},
  author={Langlois, Dominic and Chartier, Sylvain and Gosselin, Dominique},
  journal={Tutorials in Quantitative Methods for Psychology},
  volume={6},
  number={1},
  pages={31--38},
  year={2010},
  publisher={Citeseer}
}
% PCA
@book{PCA_jolliffe2002principal,
  title={Principal component analysis},
  author={Jolliffe, Ian},
  year={2002},
  publisher={John Wiley \& Sons}
}
% Non-negative matrix Factorization (NMF)
@article{NMF_lee1999learning,
  title={Learning the parts of objects by non-negative matrix factorization},
  author={Lee, Daniel D and Seung, H Sebastian},
  journal={Nature},
  volume={401},
  number={6755},
  pages={788--791},
  year={1999},
  publisher={Nature Publishing Group}
}

% OTHERS

% Descripció: Aquest article ensenya una tècnica de clustering basada en deep learning per a la segmentació i separació d'àudio en pistes individuals.
@inproceedings{hershey2016deep,
  title={Deep clustering: Discriminative embeddings for segmentation and separation},
  author={Hershey, John R and Chen, Zhuo and Le Roux, Jonathan and et al.},
  booktitle={2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={31--35},
  year={2016},
  organization={IEEE}
}

% Descripció: Aquest article presenta una arquitectura de xarxa neuronal convolucional per a la separació de veus en música polifònica.
@inproceedings{grill2017two,
  title={Two-stage singing voice separation via deep convolutional neural networks},
  author={Grill, Thomas and Schluter, Jan and Ney, Hermann},
  booktitle={2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={121--125},
  year={2017},
  organization={IEEE}
}

%% CNN
% Descripció: Aquest article introdueix una arquitectura de xarxa neuronal convolucional (CNN) per a la separació de veus en àudio musical.
@article{CNN_jansson2017singing,
  title={Singing voice separation with deep u-net convolutional networks},
  author={Jansson, Andreas and Humphrey, Eric J and Montecchio, Nicola and Bittner, Rachel M and Kumar, Anssi and Weyde, T},
  journal={2017 25th European Signal Processing Conference (EUSIPCO)},
  pages={23--27},
  year={2017},
  organization={IEEE}
}

% Descripció: Aquest article presenta una arquitectura de xarxa neuronal per a la separació de pistes d'àudio basada en múltiples escales.
@inproceedings{lva2018waveunet,
  title={Wave-u-net: A multi-scale neural network for end-to-end audio source separation},
  author={Lva, {\'E}douard and Rolland, Paul and Plumbley, Mark D},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={321--325},
  year={2018},
  organization={IEEE}
}

% Descripció: Aquest article presenta una eina d'avaluació transparent per a mètriques comunes en recuperació de informació musical (MIR).
@inproceedings{raffel2014mir_eval,
  title={mir eval: A transparent implementation of common mir metrics},
  author={Raffel, Colin and Ellis, Daniel PW},
  booktitle={Proceedings of the 15th International Conference on Music Information Retrieval (ISMIR)},
  year={2014}
}

% Descripció: Aquest article presenta una millora en el model d'anàlisi multipitch per a la transcripció automàtica de música.
@article{pardo2002improved,
  title={An improved multipitch analysis model},
  author={Pardo, Bryan},
  journal={ICMC Proceedings},
  volume={2},
  pages={35--38},
  year={2002}
}

% Descripció: Aquest article presenta un estimador de freqüència fonamental per a la transcripció automàtica de veu i música.
@inproceedings{abdallah2004fundamental,
  title={A fundamental frequency estimator for speech and music},
  author={Abdallah, Samer A and Plumbley, Mark D},
  booktitle={2004 IEEE International Conference on Acoustics, Speech, and Signal Processing},
  volume={3},
  pages={iii--421},
  year={2004},
  organization={IEEE}
}

% Descripció: Aquest article presenta reptes i direccions futures en la transcripció automàtica de música.
@inproceedings{benetos2013automatic,
  title={Automatic music transcription: Challenges and future directions},
  author={Benetos, Emmanouil and Dixon, Simon},
  booktitle={Proceedings of the 14th International Society for Music Information Retrieval Conference (ISMIR)},
  year={2013}
}

% Descripció: Pàgina opensource on un article explica diverses formes de processar l'àudio per a la utilització de ML.
@misc{audio-processing-ML, 
  title={An introduction to audio processing and machine learning using Python}, 
  url={https://opensource.com/article/19/9/audio-processing-machine-learning-python}, journal={Opensource.com}, 
  author={Singh, Jyotika}
} 

% Descripció: Extret del GitHub: https://github.com/deezer/spleeter/tree/master?tab=readme-ov-file --> Serveix per fer la separació de pistes donat un àudio.
@article{spleeter2020,
  doi = {10.21105/joss.02154},
  url = {https://doi.org/10.21105/joss.02154},
  year = {2020},
  publisher = {The Open Journal},
  volume = {5},
  number = {50},
  pages = {2154},
  author = {Romain Hennequin and Anis Khlif and Felix Voituret and Manuel Moussallam},
  title = {Spleeter: a fast and efficient music source separation tool with pre-trained models},
  journal = {Journal of Open Source Software},
  note = {Deezer Research}
}

% Descripció: Extret del GitHub: https://github.com/Music-and-Culture-Technology-Lab/omnizart?tab=readme-ov-file --> Omnizard permet la automatització de la transcripció de música (Fer la meva part de pista -> MIDI, bàsicament)
@article{Omnizard-Wu2021,
  doi = {10.21105/joss.03391},
  url = {https://doi.org/10.21105/joss.03391},
  year = {2021},
  publisher = {The Open Journal},
  volume = {6},
  number = {68},
  pages = {3391},
  author = {Yu-Te Wu and Yin-Jyun Luo and Tsung-Ping Chen and I-Chieh Wei and Jui-Yang Hsu and Yi-Chin Chuang and Li Su},
  title = {Omnizart: A General Toolbox for Automatic Music Transcription},
  journal = {Journal of Open Source Software}
}

% Descripció: Extret del GitHub: https://github.com/CPJKU/partitura --> Paritura permet generar partitures donades notes en un cert format, com pot ser el MIDI.
@inproceedings{partitura_mec,
  title={{Partitura: A Python Package for Symbolic Music Processing}},
  author={Cancino-Chac\'{o}n, Carlos Eduardo and Peter, Silvan David and Karystinaios, Emmanouil and Foscarin, Francesco and Grachten, Maarten and Widmer, Gerhard},
  booktitle={{Proceedings of the Music Encoding Conference (MEC2022)}},
  address={Halifax, Canada},
  year={2022}
}

% Descripció: Dona informació sobre la transcripció de música
@Article{music-transcription-app132111882,
AUTHOR = {Bhattarai, Bhuwan and Lee, Joonwhoan},
TITLE = {A Comprehensive Review on Music Transcription},
JOURNAL = {Applied Sciences},
VOLUME = {13},
YEAR = {2023},
NUMBER = {21},
ARTICLE-NUMBER = {11882},
URL = {https://www.mdpi.com/2076-3417/13/21/11882},
ISSN = {2076-3417},
DOI = {10.3390/app132111882}
}

% Descripció: Llibreria de Python music21. Crec que és la cita correcta, tot i que no he trobat la cita del lloc oficial. REVISAR
@inproceedings{music21-conf/ismir/CuthbertA10,
  added-at = {2020-03-12T00:00:00.000+0100},
  author = {Cuthbert, Michael Scott and Ariza, Christopher},
  biburl = {https://www.bibsonomy.org/bibtex/2655eb165e9efd7371a52cc1ce2d4efab/dblp},
  booktitle = {ISMIR},
  crossref = {conf/ismir/2010},
  editor = {Downie, J. Stephen and Veltkamp, Remco C.},
  ee = {http://ismir2010.ismir.net/proceedings/ismir2010-108.pdf},
  interhash = {75ae23495cb8183efb69481e6ad51a5f},
  intrahash = {655eb165e9efd7371a52cc1ce2d4efab},
  isbn = {978-90-393-53813},
  keywords = {dblp},
  pages = {637-642},
  publisher = {International Society for Music Information Retrieval},
  timestamp = {2020-03-13T13:00:05.000+0100},
  title = {Music21: A Toolkit for Computer-Aided Musicology and Symbolic Music Data.},
  url = {http://dblp.uni-trier.de/db/conf/ismir/ismir2010.html#CuthbertA10},
  year = 2010
}

% Descripció: Mètriques Quantitatives, SNR
@ARTICLE{Johnson:2006_SNR,
AUTHOR = {Johnson, D. H.},
TITLE   = {{S}ignal-to-noise ratio},
YEAR    = {2006},
JOURNAL = {Scholarpedia},
VOLUME  = {1},
NUMBER  = {12},
PAGES   = {2088},
DOI     = {10.4249/scholarpedia.2088},
NOTE    = {revision \#126771}
}

% Descripció: Mètriques Quantitatives, R squared (R^2)
@article{akossou2013impact_r_squared,
  title={Impact of data structure on the estimators R-square and adjusted R-square in linear regression},
  author={Akossou, AYJ and Palm, Rodolphe},
  journal={Int. J. Math. Comput},
  volume={20},
  number={3},
  pages={84--93},
  year={2013}
}

% Descripció: Mètriques Quantitatives, MSE
@INPROCEEDINGS{5937917_MSE,
  author={Sarbishei, O. and Radecka, K.},
  booktitle={2011 IEEE International Symposium of Circuits and Systems (ISCAS)}, 
  title={Analysis of Mean-Square-Error (MSE) for fixed-point FFT units}, 
  year={2011},
  volume={},
  number={},
  pages={1732-1735},
  keywords={Quantization;Optimization;Algorithm design and analysis;Hardware;Signal processing algorithms;Digital video broadcasting;Robustness},
  doi={10.1109/ISCAS.2011.5937917}}


@article{CNN_Stöter2019, doi = {10.21105/joss.01667}, url = {https://doi.org/10.21105/joss.01667}, year = {2019}, publisher = {The Open Journal}, volume = {4}, number = {41}, pages = {1667}, author = {Fabian-Robert Stöter and Stefan Uhlich and Antoine Liutkus and Yuki Mitsufuji}, title = {Open-Unmix - A Reference Implementation for Music Source Separation}, journal = {Journal of Open Source Software} }

@inproceedings{RNN_luo2020dual,
  title={Dual-path rnn: efficient long sequence modeling for time-domain single-channel speech separation},
  author={Luo, Yi and Chen, Zhuo and Yoshioka, Takuya},
  booktitle={ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={46--50},
  year={2020},
  organization={IEEE}
}
% RNN
@inproceedings{wang2018supervised,
  title={Supervised reinforcement learning with recurrent neural network for dynamic treatment recommendation},
  author={Wang, Lu and Zhang, Wei and He, Xiaofeng and Zha, Hongyuan},
  booktitle={Proceedings of the 24th ACM SIGKDD international conference on knowledge discovery \& data mining},
  pages={2447--2456},
  year={2018}
}

@article{hennequin2020spleeter,
  title={Spleeter: a fast and efficient music source separation tool with pre-trained models},
  author={Hennequin, Romain and Khlif, Anis and Voituret, Felix and Moussallam, Manuel},
  journal={Journal of Open Source Software},
  volume={5},
  number={50},
  pages={2154},
  year={2020}
}

@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={Medical image computing and computer-assisted intervention--MICCAI 2015: 18th international conference, Munich, Germany, October 5-9, 2015, proceedings, part III 18},
  pages={234--241},
  year={2015},
  organization={Springer}
}

@misc{musdb18,
  author       = {Rafii, Zafar and
                  Liutkus, Antoine and
                  Fabian-Robert St{\"o}ter and
                  Mimilakis, Stylianos Ioannis and
                  Bittner, Rachel},
  title        = {The {MUSDB18} corpus for music separation},
  month        = dec,
  year         = 2017,
  doi          = {10.5281/zenodo.1117372},
  url          = {https://doi.org/10.5281/zenodo.1117372}
}

@article{zeng2021musicbert,
  title={Musicbert: Symbolic music understanding with large-scale pre-training},
  author={Zeng, Mingliang and Tan, Xu and Wang, Rui and Ju, Zeqian and Qin, Tao and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:2106.05630},
  year={2021}
}

@article{hawthorne2018enabling,
  title={Enabling factorized piano music modeling and generation with the MAESTRO dataset},
  author={Hawthorne, Curtis and Stasyuk, Andriy and Roberts, Adam and Simon, Ian and Huang, Cheng-Zhi Anna and Dieleman, Sander and Elsen, Erich and Engel, Jesse and Eck, Douglas},
  journal={arXiv preprint arXiv:1810.12247},
  year={2018}
}

@article{sturm2016music,
  title={Music transcription modelling and composition using deep learning},
  author={Sturm, Bob L and Santos, Joao Felipe and Ben-Tal, Oded and Korshunova, Iryna},
  journal={arXiv preprint arXiv:1604.08723},
  year={2016}
}

@article{hawthorne2017onsets,
  title={Onsets and frames: Dual-objective piano transcription},
  author={Hawthorne, Curtis and Elsen, Erich and Song, Jialin and Roberts, Adam and Simon, Ian and Raffel, Colin and Engel, Jesse and Oore, Sageev and Eck, Douglas},
  journal={arXiv preprint arXiv:1710.11153},
  year={2017}
}
@article{langlois2010introduction,
  title={An introduction to independent component analysis: InfoMax and FastICA algorithms},
  author={Langlois, Dominic and Chartier, Sylvain and Gosselin, Dominique},
  journal={Tutorials in Quantitative Methods for Psychology},
  volume={6},
  number={1},
  pages={31--38},
  year={2010},
  publisher={Citeseer}
}